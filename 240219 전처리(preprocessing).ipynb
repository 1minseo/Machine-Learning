{"cells":[{"cell_type":"markdown","metadata":{"id":"rLGhbEiOoAR7"},"source":["# 텍스트 전처리 (Text Preprocessing)\n","\n","*   텍스트를 자연어 처리를 위해 용도에 맞도록 사전에 표준화하는 작업\n","*   텍스트 내 정보를 유지하고, 중복을 제거하여 분석 효율성을 높이기 위해 전처리를 수행\n"]},{"cell_type":"markdown","metadata":{"id":"E585k45HDx5E"},"source":["### 1) 토큰화 (Tokenization)\n","* 텍스트를 자연어 처리를 위해 분리 하는 것을\n","* 토큰화는 단어별로 분리하는 \"단어 토큰화(Word Tokenization)\"와 문장별로 분리하는 \"문장 토큰화(Sentence Tokenization)\"로 구분\n","\n","(이후 실습에서는 단어 토큰화를 \"토큰화\"로 통일하여 칭하도록 한다)"]},{"cell_type":"markdown","metadata":{"id":"senwNSwgDzQc"},"source":["### 2) 품사 부착(PoS Tagging)\n","* 각 토큰에 품사 정보를 추가\n","* 분석 시에 불필요한 품사를 제거하거나 (예. 조사, 접속사 등) 필요한 품사를 필터링하기 위해 사용"]},{"cell_type":"markdown","metadata":{"id":"R15ri5czDyzc"},"source":["### 3) 개체명 인식 (NER, Named Entity Recognition)\n","* 각 토큰의 개체 구분(기관, 인물, 지역, 날짜 등) 태그를 부착\n","* 텍스트가 무엇과 관련되어 있는지 구분하기 위해 사용\n","* 예를 들어, 과일의 apple과 기업의 apple을 구분하는 방법이 개체명 인식임"]},{"cell_type":"markdown","metadata":{"id":"Dfq99EkzD1Tk"},"source":["### 4) 원형 복원 (Stemming & Lemmatization)\n","* 각 토큰의 원형 복원을 함으로써 토큰을 표준화하여 불필요한 데이터 중복을 방지 (=단어의 수를 줄일 수 있어 연산을 효율성을 높임)\n","* 어간 추출(Stemming) : 품사를 무시하고 규칙에 기반하여 어간을 추출\n","* 표제어 추출 (Lemmatization) : 품사 정보를 유지하여 표제어 추출"]},{"cell_type":"markdown","metadata":{"id":"R5HQOjRvDxmd"},"source":["### 5) 불용어 처리 (Stopword)\n","* 자연어 처리를 위해 불필요한 요소를 제거하는 작업\n","* 불필요한 품사를 제거하는 작업과 불필요한 단어를 제거하는 작업으로 구성\n","* 불필요한 토큰을 제거함으로써 연산의 효율성을 높임"]},{"cell_type":"markdown","metadata":{"id":"QaIYJczuaS0n"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KysKAL3VlgQN"},"source":["# 1 영문 전처리 실습\n","\n","\n","NLTK lib (https://www.nltk.org/) 사용"]},{"cell_type":"markdown","metadata":{"id":"yv0ASXb8qa6H"},"source":["## 1) 영문 토큰화\n","https://www.nltk.org/api/nltk.tokenize.html"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3330,"status":"ok","timestamp":1637497813244,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"ZPZeW4nqTpZD","outputId":"e7d72c8c-74b8-4f87-9f4e-dca5016056f2"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR: Invalid requirement: '#NLTK(Natural'\n"]}],"source":["!pip install nltk #NLTK(Natural Language Toolkit): 주어진 텍스트를 단어로 토큰화"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1637497842120,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"ywTmZDer4iH-","outputId":"a71e539f-0f22-4edb-e4a9-4ccb744a9665"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Barack', 'Obama', 'likes', 'fried', 'chicken', 'very', 'much']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["#텍스트를 공백을 기준으로 단어 단위로 토큰화\n","#토큰화(tokenization): 주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업\n","#word_tokenize(): 마침표와 구두점(온점(.), 콤마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등과 같은 기호)으로 구분하여 토큰화\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","text = 'Barack Obama likes fried chicken very much'\n","word_tokens = word_tokenize(text)\n","print(word_tokens)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (2.15.0)\n","Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n","Requirement already satisfied: setuptools in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.2.2)\n","Requirement already satisfied: six>=1.12.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (7.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.5)\n","Requirement already satisfied: zipp>=0.5 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.17.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n","단어 토큰화1 : ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"]}],"source":["!pip install tensorflow\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import WordPunctTokenizer #punctuation: 구두점\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","\n","print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"]}],"source":["print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"]}],"source":["print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1637497913936,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"rygb4BNXFd13","outputId":"f8668454-9267-4c7c-fb35-6d1a7496180a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Barack', 'Obama', 'likes', 'fried', 'chicken', 'very', 'much']\n"]}],"source":["#텍스트를 특수문자를 기준으로 단어로 토큰화\n","#WordPunctTokenizer(): 알파벳이 아닌 문자를 구분하여 토큰화\n","\n","import nltk\n","from nltk.tokenize import WordPunctTokenizer\n","\n","text = 'Barack Obama likes fried chicken very much'\n","wordpuncttoken = WordPunctTokenizer().tokenize(text)\n","print(wordpuncttoken)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1637497929806,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"VrvBRJqJlitx","outputId":"7403ad8b-5b71-4916-862e-a7abb7b8b38a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Barack', 'Obama', 'likes', 'fried', 'chicken', 'very', 'much']\n"]}],"source":["#TreebankWordTokenizer() : 정규표현식에 기반한 토큰화\n","import nltk\n","from nltk.tokenize import TreebankWordTokenizer\n","\n","text = 'Barack Obama likes fried chicken very much'\n","treebankwordtoken = TreebankWordTokenizer().tokenize(text)\n","print(treebankwordtoken)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"]}],"source":["from nltk.tokenize import TreebankWordTokenizer\n","\n","tokenizer = TreebankWordTokenizer()\n","\n","text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n","print('트리뱅크 워드토크나이저 :',tokenizer.tokenize(text))\n","\n","#Penn Treebank Tokenization: 하이푼으로 구성된 단어는 하나로 유지, doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리"]},{"cell_type":"markdown","metadata":{},"source":["## 2) 영문 품사 부착 (PoS Tagging)\n","분리한 토큰마다 품사를 부착한다\n","\n","https://www.nltk.org/api/nltk.tag.html\n","\n","태크목록 : https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1637497969699,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"mHWVrEmTlosg","outputId":"ec3bd94f-9473-40f4-eba5-e891500dd3ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"text/plain":["True"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["#문장을 단어로 토큰화한 후, 각 단에 대해 품사 태깅을 수행\n","#품사 태깅(Part-of-speech tagging): 문장 내 각 단어의 품사를 식별. 문장의 구조와 의미를 파악\n","\n","from nltk import pos_tag\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1637497997852,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"jwtt2LxqlrVS","outputId":"0ddf6f41-0b6a-4811-efef-9759fbd8372d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Barack', 'NNP'), ('Obama', 'NNP'), ('likes', 'VBZ'), ('fried', 'VBN'), ('chicken', 'JJ'), ('very', 'RB'), ('much', 'JJ')]\n"]}],"source":["taggedToken = pos_tag(word_tokens)\n","print(taggedToken)\n","\n","#NNP:고유 명사, VBZ: 3인칭 단수 동사, VBN: 과거 분사, NN: 명사, RB: 부사, JJ: 형용사"]},{"cell_type":"markdown","metadata":{"id":"lDo-5-khs5Oz"},"source":["## 3) 개체명 인식 (NER, Named Entity Recognition)\n","\n","http://www.nltk.org/api/nltk.chunk.html"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1637498056852,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"Clj4X6Gilsi9","outputId":"94504b0b-cf03-4f78-86aa-3b3c682f395b"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package words to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('words')\n","nltk.download('maxent_ne_chunker') #개체명으로 추정되는 단어들을 특별한 태그로 묶어 개체명이라는 정보를 포함하는 청크(chunk)로 표시"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1637497605432,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"VdkMJHO7mBgi","outputId":"b812be8c-b229-42f1-dc54-8abc50fe7e92"},"outputs":[{"name":"stdout","output_type":"stream","text":["(S\n","  (PERSON Barack/NNP)\n","  (ORGANIZATION Obama/NNP)\n","  likes/VBZ\n","  fried/VBN\n","  chicken/JJ\n","  very/RB\n","  much/JJ)\n"]}],"source":["#토큰화된 문장에서 개체명을 인식하고 인식된 개체명을 트리 형태로 반환 (트리의 각 노드=개체명 또는 개체명이 아닌 것)\n","from nltk import ne_chunk\n","neToken = ne_chunk(taggedToken)\n","print(neToken)"]},{"cell_type":"markdown","metadata":{"id":"aHjV0h0ZtM-t"},"source":["## 4) 원형 복원\n","각 토큰의 원형을 복원하여 표준화한다. "]},{"cell_type":"markdown","metadata":{"id":"r2eCnbChtXjo"},"source":["### 4-1) 어간 추출 (Stemming)\n","\n","* 규칙에 기반하여 토큰을 표준화\n","* ning 제거, ful 제거 등\n","\n","https://www.nltk.org/api/nltk.stem.html\n","\n","규칙상세 : https://tartarus.org/martin/PorterStemmer/def.txt"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1637498104280,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"n-AvZXHLmCy2","outputId":"805fa064-5c5e-44a7-eb3c-3d37d1d7238b"},"outputs":[{"name":"stdout","output_type":"stream","text":["running -> run\n","beautiful -> beauti\n","believes -> believ\n","using -> use\n","conversation -> convers\n","organization -> organ\n","studies -> studi\n"]}],"source":["#어간 추출: 단어의 접미사나 어미를 제거하여 단어의 기본 형태인 어간을 찾는 과정\n","\n","from nltk.stem import PorterStemmer #Poter 어간 추출 알고리즘: 단어의 어미를 잘라내어 단어를 기본 형태로 만드는 데 사용\n","ps = PorterStemmer()\n","\n","#어간 추출을 수행할 단어들을 정의하고, 어간 추출을 수행한 결과를 출력\n","print(\"running -> \" + ps.stem(\"running\"))\n","print(\"beautiful -> \" + ps.stem(\"beautiful\"))\n","print(\"believes -> \" + ps.stem(\"believes\"))\n","print(\"using -> \" + ps.stem(\"using\"))\n","print(\"conversation -> \" + ps.stem(\"conversation\"))\n","print(\"organization -> \" + ps.stem(\"organization\"))\n","print(\"studies -> \" + ps.stem(\"studies\"))"]},{"cell_type":"markdown","metadata":{"id":"4haNWIcCtZza"},"source":["### 4-2) 표제어 추출 (Lemmatization)\n","\n","* 품사 정보를 보존하여 토큰을 표준화\n","\n","http://www.nltk.org/api/nltk.stem.html?highlight=lemmatizer"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1637498146950,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"MdxBuzdymR7w","outputId":"1777d052-8979-4d92-f5c8-9d99710eb913"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('wordnet')\n","\n","#WordNet: NLTK에서 제공하는 영어 어휘 DB로 동의어, 어원, 의미론적 관계 등을 포함하고 있어 자연어 처리 및 기계 학습 작업에 유용하게 활용"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1637498164095,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"2mQSzsCZmMBd","outputId":"2d928638-d8d8-4363-90b4-e034dee6f703"},"outputs":[{"name":"stdout","output_type":"stream","text":["running -> running\n","beautiful -> beautiful\n","believes -> belief\n","using -> using\n","conversation -> conversation\n","organization -> organization\n","studies -> study\n"]}],"source":["#NLTK의 WordNetLemmatizer를 사용하여 단어를 표제어 추출(=단어의 기본 형태인 표제어를 찾는 과정) => 단어의 다양한 형태를 표준화\n","\n","from nltk.stem import WordNetLemmatizer\n","wl = WordNetLemmatizer()\n","\n","print(\"running -> \" + wl.lemmatize(\"running\"))\n","print(\"beautiful -> \" + wl.lemmatize(\"beautiful\"))\n","print(\"believes -> \" + wl.lemmatize(\"believes\"))\n","print(\"using -> \" + wl.lemmatize(\"using\"))\n","print(\"conversation -> \" + wl.lemmatize(\"conversation\"))\n","print(\"organization -> \" + wl.lemmatize(\"organization\"))\n","print(\"studies -> \" + wl.lemmatize(\"studies\"))"]},{"cell_type":"markdown","metadata":{"id":"nmY_SvDMb0fz"},"source":["## 5) 불용어 처리 (Stopword)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":355,"status":"ok","timestamp":1637498256444,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"lOUE-BBKcn4S"},"outputs":[],"source":["stopPos = ['IN', 'CC', 'UH', 'TO', 'MD', 'DT', 'VBZ','VBP'] #pos=품사"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1637498257732,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"CyDJ4JiscnrY","outputId":"a5b39f43-8c67-48a9-f1d3-85c3dbb04444"},"outputs":[{"data":{"text/plain":["[(('Barack', 'NNP'), 1),\n"," (('Obama', 'NNP'), 1),\n"," (('likes', 'VBZ'), 1),\n"," (('fried', 'VBN'), 1),\n"," (('chicken', 'JJ'), 1),\n"," (('very', 'RB'), 1),\n"," (('much', 'JJ'), 1)]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["#최빈어 조회. 최빈어를 조회하여 불용어 제거 대상을 선정\n","from collections import Counter\n","Counter(taggedToken).most_common()"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1637498259362,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"zNhxqDVkcnX9","outputId":"19bc2690-af21-4f3c-c67a-a0117339ebe4"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Barack', 'Obama', 'fried', 'chicken', 'much']\n"]}],"source":["stopWord = [',','be','able','very'] #필요없는 품사와 단어를 전처리. 수동으로 제거해야함\n","\n","word = []\n","for tag in taggedToken:\n","    if tag[1] not in stopPos:\n","        if tag[0] not in stopWord:\n","            word.append(tag[0])\n","            \n","print(word)"]},{"cell_type":"markdown","metadata":{"id":"QV0orUsOb6wD"},"source":["## 6) 영문 텍스트 전처리 종합"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1637498339918,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"Pbz6tLP_mNrn","outputId":"346e8cd3-d43c-43ce-c1c1-0b73a8b495ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Obama', 'loves', 'fried', 'chicken', 'of', 'KFC']\n","[('Barack', 'NNP'), ('Obama', 'NNP'), ('likes', 'VBZ'), ('fried', 'VBN'), ('chicken', 'JJ'), ('very', 'RB'), ('much', 'JJ')]\n","(S\n","  (PERSON Barack/NNP)\n","  (ORGANIZATION Obama/NNP)\n","  likes/VBZ\n","  fried/VBN\n","  chicken/JJ\n","  very/RB\n","  much/JJ)\n","loves -> love\n","fried -> fri\n","loves -> love\n","fried -> fried\n","['Obama', 'loves', 'chicken', 'KFC']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package words to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\tjoeun\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('words')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('wordnet')\n","\n","from nltk.tokenize import TreebankWordTokenizer\n","sumtoken = TreebankWordTokenizer().tokenize(\"Obama loves fried chicken of KFC\")\n","print(sumtoken)\n","\n","from nltk import pos_tag\n","sumTaggedToken = pos_tag(sumtoken)\n","print(taggedToken)\n","\n","from nltk import ne_chunk\n","sumNeToken = ne_chunk(sumTaggedToken)\n","print(neToken)\n","\n","from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","print(\"loves -> \" + ps.stem(\"loves\"))\n","print(\"fried -> \" + ps.stem(\"fried\"))\n","\n","from nltk.stem import WordNetLemmatizer\n","wl = WordNetLemmatizer()\n","print(\"loves -> \" + wl.lemmatize(\"loves\"))\n","print(\"fried -> \" + wl.lemmatize(\"fried\"))\n","\n","#불용어 처리\n","sumStopPos = ['IN']\n","sumStopWord = ['fried']\n","\n","#(기존에 구축된)불용어 사전 다운 후 사용\n","nltk.download('stopwords')\n","from.nltk.corpus import stopwords\n","sumStopWord = stopwords.words('english')\n","\n","word = []\n","for tag in sumTaggedToken:\n","    if tag[1] not in sumStopPos:\n","        if tag[0] not in sumStopWord:\n","            word.append(tag[0])\n","            \n","print(word)"]},{"cell_type":"markdown","metadata":{"id":"BMErzPcbuYEa"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C0Dhqm4zkHXl"},"source":["# 2 한글 전처리 실습\n","영문은 공백으로 토큰화가 가능하지만, 한글의 경우 품사를 고려하여 토큰화 해야한다."]},{"cell_type":"markdown","metadata":{"id":"w09FHRgIphw5"},"source":["## 1) 한글 토큰화 및 형태소 분석"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3444,"status":"ok","timestamp":1637498385232,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"Xj3gdRSzhC8n","outputId":"70473af6-cff9-4836-b6be-b8827a41806d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: konlpy in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from konlpy) (1.5.0)\n","Requirement already satisfied: lxml>=4.1.0 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from konlpy) (5.1.0)\n","Requirement already satisfied: numpy>=1.6 in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in c:\\users\\tjoeun\\miniconda3\\envs\\chatbot\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"]}],"source":["#한국어 자연어 처리를 위한 라이브러리 'konlpy' 설치\n","!pip install konlpy"]},{"cell_type":"markdown","metadata":{"id":"5IZWN4xX4HXW"},"source":["한글 자연어처리기 비교\n","\n","https://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221337575742"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5172,"status":"ok","timestamp":1637498423335,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"__e0d_9Svzor","outputId":"63801f52-5338-4b0c-97de-cb092fb2ec19"},"outputs":[{"name":"stdout","output_type":"stream","text":["['인간', '이', '컴퓨터', '와', '대화', '하', '고', '있', '다는', '것', '을', '깨닫', '지', '못하', '고', '인간', '과', '대화', '를', '계속', '하', 'ㄹ', '수', '있', '다면', '컴퓨터', '는', '지능', '적', '이', 'ㄴ', '것', '으로', '간주', '되', 'ㄹ', '수', '있', '습니다', '.']\n"]}],"source":["#코모란(Komoran; Korean Morphological ANalyzer) 토큰화\n","#한국어 텍스트를 형태소 분석하여 형태소로 분리하고, 분리된 형태소들을 출력\n","\n","from konlpy.tag import Komoran\n","komoran= Komoran()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으로 간주될 수 있습니다.\"\n","komoran_tokens = komoran.morphs(kor_text)\n","print(komoran_tokens)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1776,"status":"ok","timestamp":1637498425891,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"0ZD4PsSCeztM","outputId":"c87f1bfc-c1b2-4aa5-c39e-6e3dcdec5538"},"outputs":[{"name":"stdout","output_type":"stream","text":["['인간', '이', '컴퓨터', '와', '대화', '하고', '있', '다는', '것', '을', '깨닫', '지', '못하', '고', '인간', '과', '대화', '를', '계속', '하', 'ㄹ', '수', '있', '다면', '컴퓨터', '는', '지능적', '이', 'ㄴ', '것', '으로', '간주', '되', 'ㄹ', '수', '있', '습니다', '.']\n"]}],"source":["#한나눔(Hannanum) 토큰화\n","from konlpy.tag import Hannanum\n","hannanum= Hannanum()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으로 간주될 수 있습니다.\"\n","hannanum_tokens = hannanum.morphs(kor_text)\n","print(hannanum_tokens)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1637498425891,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"ORRFr8tHe1VX","outputId":"7b54cdb1-071a-4576-9791-ae94ca9548ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["['인간', '이', '컴퓨터', '와', '대화', '하고', '있다는', '것', '을', '깨닫지', '못', '하고', '인간', '과', '대화', '를', '계속', '할', '수', '있다면', '컴퓨터', '는', '지능', '적', '인', '것', '으로', '간주', '될', '수', '있습니다', '.']\n"]}],"source":["#Okt(Open-source Korean Text Processor) 토큰화\n","from konlpy.tag import Okt\n","okt= Okt()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으로 간주될 수 있습니다.\"\n","okt_tokens = okt.morphs(kor_text)\n","print(okt_tokens)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2488,"status":"ok","timestamp":1637498428373,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"COrUs_nHe26J","outputId":"60d762d4-234f-40a2-8873-2738658193bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["['인간', '이', '컴퓨터', '와', '대화', '하', '고', '있', '다는', '것', '을', '깨닫', '지', '못하', '고', '인간', '과', '대화', '를', '계속', '하', 'ㄹ', '수', '있', '다면', '컴퓨터', '는', '지능', '적', '이', 'ㄴ', '것', '으로', '간주', '되', 'ㄹ', '수', '있', '습니다', '.']\n"]}],"source":["#꼬꼬마(Kkma) 토큰화\n","from konlpy.tag import Kkma\n","kkma= Kkma()\n","kor_text = \"인간이 컴퓨터와 대화하고 있다는 것을 깨닫지 못하고 인간과 대화를 계속할 수 있다면 컴퓨터는 지능적인 것으로 간주될 수 있습니다.\"\n","kkma_tokens = kkma.morphs(kor_text)\n","print(kkma_tokens)"]},{"cell_type":"markdown","metadata":{"id":"2M7nyptjunTG"},"source":["## 2) 한글 품사 부착 (PoS Tagging)\n","\n","PoS Tag 목록\n","\n","https://docs.google.com/spreadsheets/u/1/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1637498506787,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"2t6txrctj8nC","outputId":"2bb6e5b4-93f4-44f3-fe04-9c70006f9335"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('인간', 'NNG'), ('이', 'MM'), ('컴퓨터', 'NNG'), ('오', 'VV'), ('아', 'EC'), ('대화', 'NNG'), ('하', 'NNG'), ('고', 'MM'), ('있', 'VV'), ('달', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('을', 'NNG'), ('깨닫', 'VV'), ('지', 'NNB'), ('못', 'MAG'), ('하', 'MAG'), ('고', 'MM'), ('인간', 'NNG'), ('과', 'NNG'), ('대화', 'NNG'), ('를', 'JKO'), ('계속', 'MAG'), ('하', 'NNG'), ('ㄹ', 'NA'), ('수', 'NNB'), ('있', 'VV'), ('다면', 'NNG'), ('컴퓨터', 'NNG'), ('늘', 'VV'), ('ㄴ', 'ETM'), ('지능', 'NNP'), ('적', 'NNB'), ('이', 'MM'), ('ㄴ', 'JX'), ('것', 'NNB'), ('으로', 'JKB'), ('간주', 'NNG'), ('되', 'NNB'), ('ㄹ', 'NA'), ('수', 'NNB'), ('있', 'VV'), ('습니다', 'EC'), ('.', 'SF')]\n"]}],"source":["#코모란 품사 태깅 (42개로)\n","komoranTag = []\n","for token in komoran_tokens:\n","    komoranTag += komoran.pos(token)\n","print(komoranTag)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1637498508812,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"msdBCzI6iA2w","outputId":"27016e8a-d535-4595-cd12-d6427a24ce62"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('인간', 'N'), ('이', 'M'), ('컴퓨터', 'N'), ('와', 'I'), ('대화', 'N'), ('하', 'P'), ('고', 'E'), ('있', 'N'), ('다', 'M'), ('는', 'J'), ('것', 'N'), ('을', 'N'), ('깨닫', 'N'), ('지', 'N'), ('못하', 'P'), ('어', 'E'), ('고', 'M'), ('인간', 'N'), ('과', 'N'), ('대화', 'N'), ('를', 'N'), ('계속', 'M'), ('하', 'I'), ('ㄹ', 'N'), ('수', 'N'), ('있', 'N'), ('다면', 'N'), ('컴퓨터', 'N'), ('늘', 'P'), ('ㄴ', 'E'), ('지능적', 'N'), ('이', 'M'), ('ㄴ', 'N'), ('것', 'N'), ('으', 'N'), ('로', 'J'), ('간주', 'N'), ('되', 'N'), ('ㄹ', 'N'), ('수', 'N'), ('있', 'N'), ('슬', 'P'), ('ㅂ니다', 'E'), ('.', 'S')]\n"]}],"source":["#한나눔(Hannanum) 품사 태깅 (9개로)\n","hannanumTag = []\n","for token in hannanum_tokens:\n","    hannanumTag += hannanum.pos(token)\n","print(hannanumTag)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1637498509497,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"dpe14zC3iCFi","outputId":"8deedec9-aa6a-4881-cd0d-d46abd1a8dc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('인간', 'Noun'), ('이', 'Noun'), ('컴퓨터', 'Noun'), ('와', 'Verb'), ('대화', 'Noun'), ('하고', 'Verb'), ('있다는', 'Adjective'), ('것', 'Noun'), ('을', 'Josa'), ('깨닫지', 'Verb'), ('못', 'Noun'), ('하고', 'Verb'), ('인간', 'Noun'), ('과', 'Noun'), ('대화', 'Noun'), ('를', 'Noun'), ('계속', 'Noun'), ('할', 'Verb'), ('수', 'Noun'), ('있다면', 'Adjective'), ('컴퓨터', 'Noun'), ('는', 'Verb'), ('지능', 'Noun'), ('적', 'Noun'), ('인', 'Noun'), ('것', 'Noun'), ('으로', 'Josa'), ('간주', 'Noun'), ('될', 'Verb'), ('수', 'Noun'), ('있습니다', 'Adjective'), ('.', 'Punctuation')]\n"]}],"source":["#Okt(Open-source Korean Processor) 품사 태깅\n","oktTag = []\n","for token in okt_tokens:\n","    oktTag += okt.pos(token)\n","print(oktTag)\n","\n","#100% 정확하지 않음 => 한국어의 한계"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1637498510029,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"xNQBKdYaiDd0","outputId":"11d1c039-9b9a-48d3-9321-8e5fdbe6b9c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('인간', 'NNG'), ('이', 'NNG'), ('컴퓨터', 'NNG'), ('오', 'VA'), ('아', 'ECS'), ('대화', 'NNG'), ('하', 'NNG'), ('고', 'NNG'), ('있', 'VA'), ('달', 'VV'), ('는', 'ETD'), ('것', 'NNB'), ('을', 'NNG'), ('깨닫', 'VV'), ('지', 'NNG'), ('못하', 'VX'), ('고', 'NNG'), ('인간', 'NNG'), ('과', 'NNG'), ('대화', 'NNG'), ('를', 'UN'), ('계속', 'MAG'), ('하', 'NNG'), ('ㄹ', 'NNG'), ('수', 'NNG'), ('있', 'VA'), ('다면', 'NNG'), ('컴퓨터', 'NNG'), ('늘', 'VA'), ('ㄴ', 'ETD'), ('지능', 'NNG'), ('적', 'NNG'), ('이', 'NNG'), ('ㄴ', 'NNG'), ('것', 'NNB'), ('으', 'UN'), ('로', 'JKM'), ('간주', 'NNG'), ('되', 'VA'), ('ㄹ', 'NNG'), ('수', 'NNG'), ('있', 'VA'), ('슬', 'VV'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n"]}],"source":["#Kkma 품사 태깅 (56개로)\n","kkmaTag = []\n","for token in kkma_tokens:\n","    kkmaTag += kkma.pos(token)\n","print(kkmaTag)"]},{"cell_type":"markdown","metadata":{"id":"VZY4s8tbuuXP"},"source":["## 3) 불용어(Stopword) 처리\n","분석에 불필요한 품사를 제거하고, 불필요한 단어(불용어)를 제거한다"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":282,"status":"ok","timestamp":1637498608107,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"Nvjk1yIYkCfj"},"outputs":[],"source":["#불용어 처리\n","stopPos = ['Suffix','Punctuation','Josa','Foreign','Alpha','Number'] #불용어 처리할 품사들 지정"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1637498608372,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"573iqrTFkcJ3"},"outputs":[],"source":["#최빈어(=가장 자주 등장하는 단어) 조회. 최빈어를 조회하여 불용어 제거 대상을 선정\n","\n","from collections import Counter\n","#Counter(oktTag).most_common()"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1637498609324,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"5lBkhHm1kYcz"},"outputs":[],"source":["stopWord = ['는','의','이','로','두고','들','를','은','과','수','했다','것','있는','한다','하는','그','있다','할','이런','되기','해야','있게','여기'] #불용어 사전에 추가하여 정제"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1637498611404,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"BJgERpoikh9s"},"outputs":[],"source":["word = []\n","for tag in oktTag:\n","    if tag[1] not in stopPos:\n","        if tag[0] not in stopWord:\n","            word.append(tag[0])"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1637498612712,"user":{"displayName":"이민호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiFPPatrtQJJCEfMd6D3DoTVRog9gVm7Ovj5Lex=s64","userId":"15829449822908558555"},"user_tz":-540},"id":"iUQTDj4KkkBN","outputId":"b9090230-cb69-418b-dc6e-62a6c45764eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["['인간', '컴퓨터', '와', '대화', '하고', '있다는', '깨닫지', '못', '하고', '인간', '대화', '계속', '있다면', '컴퓨터', '지능', '적', '인', '간주', '될', '있습니다']\n"]}],"source":["print(word)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"04 실습 - 전처리 (Preprocessing)","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
