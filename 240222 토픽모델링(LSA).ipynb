{"cells":[{"cell_type":"markdown","metadata":{"id":"Jyp5nHXQsXez"},"source":["잠재의미분석 (Latent Semantic Analysis LSA)"]},{"cell_type":"markdown","metadata":{"id":"rAQyWNVQWAh8"},"source":["##### 1) 직접 구현"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708489264810,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"TRNB7P9Y9Hav"},"outputs":[],"source":["#CountVectorizer를 사용하여 텍스트 데이터 -> 단어 빈도 행렬(DTM, Document-Term Matrix)\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","cv = CountVectorizer() #CountVectorizer 객체 생성 (텍스트를 처리하여 단어의 빈도 계산)\n","DTM = cv.fit_transform(docs).toarray() #to_array() 메소드를 사용하여 희소 행렬 -> 밀집 형태로\n","feature_name = cv.get_feature_names_out() #DTM의 열(피처)에 해당하는 단어 목록\n","word2id = cv.vocabulary_  # 딕셔너리도 따로 선헌해둔다."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708489264811,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"rofygtJm4lET","outputId":"5b9e1d0a-d41c-4b09-ae59-bfbcb4837d2c"},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n","       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n","       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n","       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n","       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n","       [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n","       [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["DTM\n","\n","#DTM(Document-Term Matrix): 문서와 단어의 관계를 표현하는 행렬. 단어가 무엇인지는 확인하기 어려움"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1708489264812,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"8hZlpNOB4tAE","outputId":"f70925b3-be41-442c-cc85-872c8f5fec6f"},"outputs":[{"data":{"text/plain":["array(['가츠동', '김치', '김치찌개', '된장', '된장찌개', '라면', '바나나', '볶음밥', '비빔밥', '사과',\n","       '소바', '스시', '짜장면', '짬뽕', '탕수육', '포도'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["cv.get_feature_names_out() #DTM의 각 열에 해당하는 단어들 확인"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1708489265221,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"vlIMXqhm9zrq","outputId":"5ae722e8-81b9-46a9-92b5-8c643d53b5d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["['포도', '바나나', '짜장면']\n","['짜장면', '짬뽕', '김치']\n","['김치', '된장찌개', '김치찌개']\n","['스시', '김치', '가츠동']\n"]}],"source":["#randomized_svd를 사용하여 특이값 분해(Singular Value Decomposition, SVD) 수행 -> 문서-단어행렬(DTM)을 주어진 차원(K)으로 차원 축소\n","#각 주제에 속하는 상위 3개의 단어 출력. 각 주제의 주요 키워드 확인\n","\n","from sklearn.decomposition import randomized_svd #특이값 분해(SVD)의 무작위 버전 제공\n","\n","U, s, VT = randomized_svd(DTM, n_components = k, n_iter=10, random_state = 0) #randomized_svd 사용하여 DTM을 주워진 차원(K)로 차원 축소\n","\n","for topic in VT : #축소된 행렬 VT의 각 행=주제(topic). VT의 각 행에 대해 반복\n","  print([feature_name[i] for i in topic.argsort()[::-1][:3]])"]},{"cell_type":"markdown","metadata":{"id":"31Kn3iEWLDz9"},"source":["##### 2) sklearn 활용"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708489265222,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"2LVVXaR4EJCZ"},"outputs":[],"source":["doc_ls = ['바나나 사과 포도 포도 ',\n","         '사과 포도',\n","         '포도 바나나',\n","         '짜장면 짬뽕 탕수육',\n","         '볶음밥 탕수육',\n","         '짜장면 짬뽕',\n","         '라면 스시',\n","         '스시 ',\n","         '가츠동 스시 소바',\n","         '된장찌개 김치찌개 김치',\n","         '김치 된장 ',\n","         '비빔밥 김치'\n","         ]\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708489265222,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"ZOPy5VKzKr8_","outputId":"610c487e-318e-4dc6-d36e-06c7c49e6952"},"outputs":[{"data":{"text/plain":["array([[ 0.73533636,  0.65297083,  0.10110344,  0.01060989],\n","       [ 0.61363093,  0.60431072,  0.10524359,  0.01238742],\n","       [ 0.7984386 ,  0.26045607, -0.01831414, -0.00672613],\n","       [ 0.53305177, -0.56031022, -0.42213385, -0.33044636],\n","       [ 0.14418228, -0.21254471, -0.23191093, -0.2625725 ],\n","       [ 0.54801361, -0.53006465, -0.34992723, -0.22258649],\n","       [ 0.406527  , -0.48568088,  0.49477573,  0.00250927],\n","       [ 0.18446514, -0.3626629 ,  0.77698444,  0.02307865],\n","       [ 0.12607679, -0.273366  ,  0.66103424,  0.02235352],\n","       [ 0.07786141, -0.11341968, -0.1305914 ,  0.67529106],\n","       [ 0.35852776, -0.33318007, -0.21842001,  0.55386528],\n","       [ 0.09205415, -0.13080845, -0.1456878 ,  0.72457634]])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["#TD-IDF를 사용하여 문서를 벡터화 -> Truncated SVD를 사용하여 주어진 토픽의 수로 차원 축소\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer #TF-IDF 벡터화를 위한 TfidfVectorizer\n","from sklearn.decomposition import TruncatedSVD\n","\n","n_topics = 4 #토픽의 수=4\n","\n","tfidfv = TfidfVectorizer() #TfidfVectorizer 객체 생성. TF-IDF 가충지를 사용하여 단어를 벡터화\n","tfidf = tfidfv.fit_transform(docs) #TF-IDF 벡터화. docs=입력된 문서들\n","svd = TruncatedSVD(n_components = n_topics, algorithm = 'randomized', n_iter=100) #n_components: 주어진 토픽의 수\n","svd.fit_transform(tfidf) #문서집합을 토픽의 수로 차원 축소"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1708489265222,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"XQPbtrruV_rB","outputId":"3eb5da58-0289-4ec2-9069-b813cace3839"},"outputs":[{"data":{"text/plain":["['포도', '짜장면', '바나나']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#Truncated SVD를 통해 추출된 첫 번째 주제의 주요 단어들을 출력 => 주요 주제 파악\n","\n","[feature_name[i] for i in svd.components_[0].argsort()[::-1][:3]]"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708489265222,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"fkHor8JeRuFz","outputId":"3dfde4a3-dd30-46d9-f949-d99f3bb6e46b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['포도', '짜장면', '바나나']\n","['포도', '사과', '바나나']\n","['스시', '소바', '가츠동']\n","['김치', '비빔밥', '된장찌개']\n"]}],"source":["#Truncated SVD를 통해 추출된 각 주제의 상위 3개의 주요 단어를 출력\n","\n","for idx, topic in enumerate(svd.components_) :\n","  print([feature_name[i] for i in topic.argsort()[::-1][:3]])\n","\n","#svd.components_: Truncated SVD를 통해 추출된 주성분들을 담고 있는 배열\n","#enumerate(): 주성분들의 인덱스와 해당 주성분 순회\n","#topic.argsort(): 각 주제의 주성분을 구성하는 값들을 정렬하여 그에 해당하는 인덱스들 반환 => 단어의 중요도"]},{"cell_type":"markdown","metadata":{"id":"QiJXdInJLn-4"},"source":["##### 3) gensim 활용"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708489265222,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"lz82ZZpkLr9I"},"outputs":[],"source":["docs = ['바나나 사과 포도 포도',\n","         '사과 포도',\n","         '포도 바나나',\n","         '짜장면 짬뽕 탕수욕',\n","         '볶음밥 탕수욕',\n","         '짜장면 짬뽕',\n","         '라면 스시',\n","         '스시',\n","         '가츠동 스시 소바',\n","         '된장찌개 김치찌개 김치',\n","         '김치 된장',\n","         '비빔밥 김치'\n","         ]"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708489265222,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"JjZIWeWuL1NT","outputId":"88d79155-ad83-4c7c-bed6-6807dd7fac99"},"outputs":[{"data":{"text/plain":["['바나나', '사과', '포도', '포도']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#'docs'라는 리스트 안에 있는 각 문서들을 공백을 기준으로 분리하여 토큰화한 결과를 리스트 'docs_ls'에 저장\n","\n","doc_ls = [doc.split() for doc in docs]\n","doc_ls[0] #첫 번째 문서를 토큰화한 결과"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":894,"status":"ok","timestamp":1708489266113,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"eCcg7TSHL5ZR"},"outputs":[],"source":["#Latent Semantic Analysis (LSA) 수행 -> 4개의 주제를 가진 LSI 모델 생성\n","\n","from gensim import corpora\n","from gensim.models import LsiModel\n","from gensim.models import TfidfModel\n","\n","id2word = corpora.Dictionary(doc_ls)\n","corpus_TDM = [id2word.doc2bow(t) for t in doc_ls]\n","model_LSA = LsiModel(corpus_TDM, id2word=id2word, num_topics = 4)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708489266113,"user":{"displayName":"김영우","userId":"10855110552143292864"},"user_tz":-540},"id":"iYyc-JmCXfun","outputId":"48d82089-d023-453d-ca25-9d149a2b158d"},"outputs":[{"data":{"text/plain":["[(0, '0.816*\"포도\" + 0.408*\"사과\" + 0.408*\"바나나\"'),\n"," (1, '-0.612*\"짜장면\" + -0.612*\"짬뽕\" + -0.484*\"탕수욕\"'),\n"," (2, '-0.813*\"김치\" + -0.337*\"된장찌개\" + -0.337*\"김치찌개\"'),\n"," (3, '-0.815*\"스시\" + -0.368*\"가츠동\" + -0.368*\"소바\"')]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model_LSA.print_topics(4, 3)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
